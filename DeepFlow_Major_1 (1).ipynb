{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "089be956-60e7-4400-9c48-ef1155d9ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Raman\\AppData\\Local\\Temp\\ipykernel_21760\\2536131177.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[self.col + \"_encoded\"].fillna(self.global_mean_, inplace=True)\n",
      "C:\\Users\\Venkat Raman\\AppData\\Local\\Temp\\ipykernel_21760\\2536131177.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[self.col + \"_encoded\"].fillna(self.global_mean_, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE for linear regression model: 0.3528842843861324\n",
      "RMSLE for random forest model: 0.2792275099376999\n",
      "RMSE for test data for linear regression model in comparison with benchmark: 0.4933582544174968\n",
      "RMSE for test data for random forest in comparison with the benchmark: 0.2651757357892384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat Raman\\AppData\\Local\\Temp\\ipykernel_21760\\2536131177.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[self.col + \"_encoded\"].fillna(self.global_mean_, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# TargetEncoder class for ModelID which will be used later as it has too many values to be used as a one hot encoded columns\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col, target):\n",
    "        self.col = col\n",
    "        self.target = target\n",
    "        self.mapping_ = None\n",
    "        self.global_mean_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        df = pd.concat([X, y], axis=1)\n",
    "        self.mapping_ = df.groupby(self.col)[self.target].mean()\n",
    "        self.global_mean_ = y.mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.col + \"_encoded\"] = X[self.col].map(self.mapping_)\n",
    "        X[self.col + \"_encoded\"].fillna(self.global_mean_, inplace=True)\n",
    "        return X\n",
    "\n",
    "# Loading data\n",
    "df_sales = pd.read_csv(r\"C:\\Adithya\\IITK\\IITK EDU\\Stamatics- Deep Flow\\datasheet\\bluebook-for-bulldozers\\TrainAndValid.csv\", low_memory=False)\n",
    "df_machine_info = pd.read_csv(r\"C:\\Adithya\\IITK\\IITK EDU\\Stamatics- Deep Flow\\datasheet\\bluebook-for-bulldozers\\Machine_Appendix.csv\")\n",
    "\n",
    "df_machine_info = df_machine_info.drop(columns=['MachineID']).drop_duplicates(subset='ModelID')\n",
    "df = df_sales.merge(df_machine_info, on='ModelID', how='left')\n",
    "\n",
    "#Extracting useful info from saledate that helps model depreciation/inflation from manufactured data\n",
    "df['saledate'] = pd.to_datetime(df['saledate'], errors='coerce')\n",
    "df['saleYear'] = df['saledate'].dt.year.astype(int)\n",
    "df['saleMonth'] = df['saledate'].dt.month.astype(int)\n",
    "\n",
    "# Handling NaNs, different strategies for different columns based on observation\n",
    "mean_impute = ['MachineHoursCurrentMeter', 'PrimaryLower', 'PrimaryUpper']\n",
    "none_impute = [\n",
    "    'Forks', 'Pad_Type', 'Ride_Control', 'Turbocharged', 'Blade_Extension', 'Blade_Width',\n",
    "    'Enclosure_Type', 'Scarifier', 'Tip_Control', 'Tire_Size', 'Coupler_System',\n",
    "    'Grouser_Tracks', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb', 'Pattern_Changer', 'Blade_Type',\n",
    "    'ProductSize', 'Drive_System', 'Enclosure', 'Stick', 'Transmission', 'Ripper', 'Coupler',\n",
    "    'Hydraulics_Flow', 'Track_Type', 'Grouser_Type', 'Travel_Controls', 'Steering_Controls', 'PrimarySizeBasis', 'Hydraulics', 'Differential_Type'\n",
    "]\n",
    "mode_impute = ['Engine_Horsepower', 'Pushblock', 'MfgYear', 'fiManufacturerID', 'fiManufacturerDesc']\n",
    "\n",
    "for col in mean_impute:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "for col in none_impute:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"None or Unspecified\")\n",
    "\n",
    "for col in mode_impute:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "#Based on a possible relation between the 2, different strategy used to fill Nans of UsageBand\n",
    "if 'UsageBand' in df.columns and 'fiProductClassDesc_x' in df.columns:\n",
    "    df['UsageBand'] = df.groupby('fiProductClassDesc_x')['UsageBand'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'None'))\n",
    "\n",
    "#Dropping redundant columns based on observations\n",
    "df.drop(columns=[\n",
    "    'saledate', 'SalesID', 'MachineID', 'datasource', 'auctioneerID',\n",
    "    'fiSecondaryDesc_x', 'fiSecondaryDesc_y', 'fiBaseModel_x', 'fiBaseModel_y',\n",
    "    'fiModelSeries_x', 'fiModelSeries_y', 'fiModelDescriptor_x', 'fiModelDescriptor_y',\n",
    "    'Backhoe_Mounting', 'Blade_Type', 'fiModelDesc_x', 'fiModelDesc_y',\n",
    "    'fiProductClassDesc_y', 'ProductGroup_y', 'ProductGroupDesc_y', 'fiManufacturerDesc'\n",
    "], inplace=True)\n",
    "\n",
    "# Preparing for encoding\n",
    "target_col = 'SalePrice'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Splitting before fitting encoder\n",
    "X_train, X_test, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Applying target encoder\n",
    "te = TargetEncoder(col='ModelID', target='SalePrice')\n",
    "te.fit(X_train, y_train)\n",
    "\n",
    "X_train = te.transform(X_train)\n",
    "X_test = te.transform(X_test)\n",
    "\n",
    "# Dropping original ModelID\n",
    "X_train.drop(columns=['ModelID'], inplace=True)\n",
    "X_test.drop(columns=['ModelID'], inplace=True)\n",
    "\n",
    "# Final feature separation\n",
    "numeric_cols = X_train.select_dtypes(include=['int32', 'int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# One-hot + scaling\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), numeric_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Training model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_transformed, y_train)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_valid_pred_lr = lr.predict(X_test_transformed)\n",
    "y_valid_pred_rf = rf.predict(X_test_transformed)\n",
    "\n",
    "# Evaluation\n",
    "print(\"RMSLE for linear regression model:\", np.sqrt(metrics.mean_squared_log_error(np.abs(y_valid), np.abs(y_valid_pred_lr))))\n",
    "print(\"RMSLE for random forest model:\", np.sqrt(metrics.mean_squared_log_error(np.abs(y_valid), np.abs(y_valid_pred_rf))))\n",
    "\n",
    "#Test Data\n",
    "test_df = pd.read_csv(r\"C:\\Adithya\\IITK\\IITK EDU\\Stamatics- Deep Flow\\datasheet\\bluebook-for-bulldozers\\Test.csv\")\n",
    "test_df = test_df.merge(df_machine_info, on='ModelID', how='left')\n",
    "\n",
    "\n",
    "test_df['saledate'] = pd.to_datetime(test_df['saledate'], errors='coerce')\n",
    "test_df['saleYear'] = test_df['saledate'].dt.year.astype(int)\n",
    "test_df['saleMonth'] = test_df['saledate'].dt.month.astype(int)\n",
    "Ids = test_df['SalesID']\n",
    "test_df.drop(columns=[\n",
    "    'saledate', 'SalesID', 'MachineID', 'datasource', 'auctioneerID',\n",
    "    'fiSecondaryDesc_x', 'fiSecondaryDesc_y', 'fiBaseModel_x', 'fiBaseModel_y',\n",
    "    'fiModelSeries_x', 'fiModelSeries_y', 'fiModelDescriptor_x', 'fiModelDescriptor_y',\n",
    "    'Backhoe_Mounting', 'Blade_Type', 'fiModelDesc_x', 'fiModelDesc_y',\n",
    "    'fiProductClassDesc_y', 'ProductGroup_y', 'ProductGroupDesc_y', 'fiManufacturerDesc'\n",
    "], inplace=True)\n",
    "\n",
    "\n",
    "for col in mean_impute:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(df[col].mean())\n",
    "for col in none_impute:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(\"None or Unspecified\")\n",
    "for col in mode_impute:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "if 'UsageBand' in test_df.columns and 'fiProductClassDesc_x' in test_df.columns:\n",
    "    test_df['UsageBand'] = test_df.groupby('fiProductClassDesc_x')['UsageBand'].transform(\n",
    "        lambda x: x.fillna(x.mode()[0] if not x.mode().empty else 'None'))\n",
    "\n",
    "test_df=te.transform(test_df)\n",
    "test_df.drop(columns=['ModelID'],inplace=True)\n",
    "\n",
    "X = preprocessor.transform(test_df)\n",
    "test_preds_lr = lr.predict(X)\n",
    "test_preds_rf = rf.predict(X)\n",
    "\n",
    "df_benchmark=pd.read_csv(r\"C:\\Adithya\\IITK\\IITK EDU\\Stamatics- Deep Flow\\datasheet\\bluebook-for-bulldozers\\random_forest_benchmark_test.csv\")\n",
    "bench_pred=df_benchmark['SalePrice']\n",
    "\n",
    "print(\"RMSE for test data for linear regression model in comparison with benchmark:\", np.sqrt(metrics.mean_squared_log_error(np.abs(test_preds_lr), np.abs(bench_pred))))\n",
    "print(\"RMSE for test data for random forest in comparison with the benchmark:\", np.sqrt(metrics.mean_squared_log_error(np.abs(test_preds_rf), np.abs(bench_pred))))\n",
    "# Save submission of rf cause it is marginally performing better than lr\n",
    "submission = pd.DataFrame({\"SalesID\": Ids, \"SalePrice\": test_preds_rf})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3d559-3056-4e50-9d14-3b18daf46207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb53a4-de40-4506-825f-e9aea0913f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
